# Ambedkar Q&A System --- Setup Guide

This project uses **LangChain + ChromaDB + FAISS + Ollama (Mistral
7B)**\
to create a fully local RAG-based Q&A system.

------------------------------------------------------------------------

## âœ… 1. Install Ollama & Pull Mistral Model

Make sure **Ollama** is installed.

Then pull the model:

    ollama pull mistral

------------------------------------------------------------------------

## âœ… 2. Clone the Repository

    git clone https://github.com/PRM710/BR_LLM.git
    cd BR_LLM

------------------------------------------------------------------------

## âœ… 3. Backend Setup

### â–¶ Step 1 --- Enter Backend Folder

    cd backend

### â–¶ Step 2 --- Create Virtual Environment

    python -m venv venv

### â–¶ Step 3 --- Activate venv

**Windows:**

    venv\Scripts\activate

**Mac/Linux:**

    source venv/bin/activate

------------------------------------------------------------------------

## âœ… 4. Install Python Dependencies (Exact Versions)

Install **in this exact order**:

    pip install langchain==0.1.16
    pip install langchain-community
    pip install langchain-text-splitters
    pip install chromadb
    pip install sentence-transformers
    pip install ollama
    pip install faiss-cpu

------------------------------------------------------------------------

## âœ… 5. Run the Backend

### â–¶ Run using Python only (simple mode)

    python main.py

### â–¶ Run API server (for frontend integration)

    uvicorn server:app --reload

API will start at:

    http://127.0.0.1:8000

------------------------------------------------------------------------

## âœ… 6. Frontend Setup (React)

### â–¶ Step 1 --- Enter frontend folder

    cd frontend

### â–¶ Step 2 --- Install dependencies

    npm install
    npm install axios

### â–¶ Step 3 --- Start development server

    npm run dev

Frontend will run on:

    http://localhost:5173

------------------------------------------------------------------------

## ðŸš€ API Endpoint

Send questions to:

    POST /ask

Body:

``` json
{ "question": "Your question here" }
```

------------------------------------------------------------------------

## ðŸŽ‰ You're Ready!

Your full RAG system (Backend + Frontend + Ollama Mistral) is now
running locally.
